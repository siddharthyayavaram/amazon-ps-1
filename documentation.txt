Data Preprocessing Documentation

Step 1: Removing unnecessary columns 

The columns 'Customer Id' and 'Artist Name' are trivial and unique. They provide no value to the 
actual final shipping cost. 
Hence, these columns are dropped from the dataframe.

Step 2: Conversion of dates into appropriate usable format

Using the datetime module 'Scheduled Date' and 'Delivery Date' columns were converted to standard 
datetime format.
Example Conversion: 06/07/15 -> 2015-06-07

Since dates themselves do not provide significant value, we calculated the difference between the
'Scheduled Date' and 'Delivery Date' to gain more easily gained insight.
If delivery date is earlier than scheduled than the duration is positive and vice versa.
Example Conversion: Scheduled Date   Delivery Date   Difference 
                      2015-06-07	  2015-06-03         4

Step 3: Simpifying the customer location

Using the whole address makes it difficult to input the location into our regressor model. Further,
using specific pincodes and locations does not provide an overall insight and would be very difficult
to numerically encode it further down the line.

So the address string was split by spaces and only the second last was taken into account (index -> -2)
which represents the state within the address.
Example Conversion: New Michelle, OH 50777 -> OH 

Step 4: Filling in the missing values using KNNimputer.


KNNimputer is a scikit-learn class used to fill out or predict the missing values in a dataset. It is a 
more useful method which works on the basic approach of the KNN algorithm rather than the naive approach 
of filling all the values with mean or the median. It is based on Euclidean distance.

Step 5: Numerical encoding for non-numeric columns

One-hot encoding using the one-hot encoder from the sklearn library for non-numerical columns.
These include 'Material','International','Express Shipment', 'Installation Included','Transport','Fragile',
'Customer Information' and 'Remote Location'.
Used the function encoder.fit-transform.

Step 6: Removing outliers from a pandas DataFrame using the IQR method

It is important to remove ouliers or anomalies/exceptions from the data so that our model doesn't overfit 
to also take those outliers into account and hence doesn't skew our reults.

Using the IQR, the outlier data points are the ones falling below Q1–1.5 IQR or above Q3 + 1.5 IQR. 
The Q1 is the 25th percentile and Q3 is the 75th percentile of the dataset, and IQR represents the 
interquartile range calculated by Q3 minus Q1 (Q3–Q1
The IQR method of removing outliers was used on the following columns:
'Height'
'Width'
'Weight'
'Price Of Sculpture'

The total number of rows went down from 6500 rows to 4234 rows after data preprocessing.

Step 7: Removing extra features to fit in with our API of benchmark shipping cost.

'Artist Reputation','Material_Aluminium','Material_Brass','Material_Bronze','Material_Clay','Material_Marble',
'Material_Stone','Material_Wood','Installation Included_No','Installation Included_Yes','Customer Information_Wealthy',
'Customer Information_Working Class'

These features have a low correlation with the cost and hence can be removed without sacrificing much accuracy.



 
